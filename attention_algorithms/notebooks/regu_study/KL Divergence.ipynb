{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7df9a138-01d2-4d0b-a045-8eff8696e532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# preparation of the environment\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "INF = 1e30\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "from os import path\n",
    "# set the repository to the git repository\n",
    "cwd = os.getcwd().split(os.path.sep)\n",
    "while cwd[-1] != \"stage_4_gm\":\n",
    "    os.chdir(\"..\")\n",
    "    cwd = os.getcwd().split(os.path.sep)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from training_bert import BertNliLight\n",
    "from regularize_training_bert import SNLIDataModule\n",
    "from regularize_training_bert import BertNliRegu\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --> from this environment\n",
    "from attention_algorithms.raw_attention import RawAttention\n",
    "from attention_algorithms.attention_metrics import normalize_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8a6743d-6ba4-4f26-8c60-c6b73e5fd090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# the different models\n",
    "models_dict = {}\n",
    "for r in [0, 0.001, 0.002, 0.003, 0.004, 0.005, 0.08, 0.1, 0.4]:\n",
    "    model = None\n",
    "    if r==0:\n",
    "        ckp = path.join(\".cache\", \"logs\", \"igrida_trained\", \"0\", \"best.ckpt\")\n",
    "        model = BertNliLight.load_from_checkpoint(ckp)\n",
    "    else :\n",
    "        ckp = path.join(\".cache\", \"logs\", \"igrida_trained\", f\"reg_mul={r}\", \"best.ckpt\")\n",
    "        model = BertNliRegu.load_from_checkpoint(ckp)\n",
    "    models_dict[f\"reg_mul={r}\"] = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b2926aa-d27c-4ef3-942e-5ab2882b980f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(\".cache\", \"raw_data\", \"e_snli\")\n",
    "\n",
    "dm = SNLIDataModule(cache=data_dir,\n",
    "                   batch_size = 1,\n",
    "                   num_workers = 4,\n",
    "                   nb_data = 99)\n",
    "\n",
    "dm.prepare_data()\n",
    "\n",
    "dm.setup(stage=\"test\")\n",
    "\n",
    "test_dataset = dm.test_set\n",
    "test_dataloader = dm.test_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbddc1c6-9634-44f9-b084-8ff11cdc30a3",
   "metadata": {},
   "source": [
    "## The KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f703a14b-8c70-4c7b-815f-3119fd04b95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99dbfda5ccb74f2398960178016ddb16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "KL_divergence_dict = {}\n",
    "\n",
    "\n",
    "for r in [0, 0.001, 0.002, 0.003, 0.004, 0.005, 0.08, 0.1, 0.4]:\n",
    "    KL_divergence_dict[f\"reg_mul={r}\"] = torch.zeros((12, 12, 99))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for id_batch, batch in tqdm(enumerate(test_dataloader), total = len(test_dataset)):\n",
    "\n",
    "        ids = batch[\"input_ids\"]\n",
    "        mk = batch[\"attention_masks\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        a_true = batch[\"annotations\"]\n",
    "        spe_tok_mask = torch.isin(ids, torch.tensor([0, 101, 102])).type(torch.uint8)[0]\n",
    "        \n",
    "        for r in [0, 0.001, 0.002, 0.003, 0.004, 0.005, 0.08, 0.1, 0.4]:\n",
    "            raw_attention_inst = RawAttention(model = models_dict[f\"reg_mul={r}\"],\n",
    "                                             input_ids = ids,\n",
    "                                             attention_mask = mk,\n",
    "                                             test_mod = False\n",
    "                                             )\n",
    "            for h in range(12):\n",
    "                for h_p in range(12):\n",
    "                    a_hat_h = raw_attention_inst.attention_tensor[0, 2, h, :, :].sum(dim=0)\n",
    "                    a_hat_h = torch.softmax(a_hat_h - INF*spe_tok_mask[0:len(raw_attention_inst.tokens)],dim=0)\n",
    "                    a_hat_h_p = raw_attention_inst.attention_tensor[0, 2, h_p, :, :].sum(dim=0)\n",
    "                    a_hat_h_p = torch.softmax(a_hat_h_p - INF*spe_tok_mask[0:len(raw_attention_inst.tokens)], dim=0)\n",
    "                    \n",
    "                    KL_divergence_dict[f\"reg_mul={r}\"][h, h_p, id_batch] = F.kl_div(a_hat_h, a_hat_h_p)                  \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd9ebe52-6b07-4f1e-8826-4e764c73db2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_s = {}\n",
    "var_s = {}\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for r in [0, 0.001, 0.002, 0.003, 0.004, 0.005, 0.08, 0.1, 0.4]:\n",
    "    mean_s[f\"reg_mul={r}\"] = KL_divergence_dict[f\"reg_mul={r}\"].mean(dim=-1)\n",
    "    var_s[f\"reg_mul={r}\"] = KL_divergence_dict[f\"reg_mul={r}\"].var(dim=-1)\n",
    "    \n",
    "    x += [f\"reg_mul={r}\"]*int(12*12)\n",
    "    \n",
    "    y += list(mean_s[f\"reg_mul={r}\"].flatten().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9bed7acd-05d1-4fd9-87fa-774ee42ff3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = sns.boxplot(x = x, y = y)\n",
    "plt.savefig(os.path.join(os.getcwd(), \".cache\", \"plots\", \"reg_compensation_study\", \"kl_divergence.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc11d20-8d87-4ca3-b437-527b164fd00d",
   "metadata": {},
   "source": [
    "## Look at the distribution for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "329aae24-f4a4-4eb9-977b-1eccbcbae144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_render(model_outputs):\n",
    "    html = ''\n",
    "    table_len = len(model_outputs['GROUNDTRUTH']['Entropy'])\n",
    "    for i in range(table_len):\n",
    "        html += '<table>'\n",
    "        html += '<tr><th></th>' # One xtra head for model's name\n",
    "        for column_name in model_outputs['GROUNDTRUTH'].keys():\n",
    "            html+= '<th>'+ column_name +'</th>'\n",
    "        html += ' </tr>'\n",
    "        for name, model_content in model_outputs.items():\n",
    "            html += '<tr>'\n",
    "            html += '<td><b>' + name + '</b></td>'\n",
    "\n",
    "            for k, output in model_content.items():\n",
    "                displ = output[i] if output is not None else 'N/A'\n",
    "                if isinstance(displ, float):\n",
    "                    displ = str(round(displ, 3))\n",
    "                html += '<td>' + displ + '</td>'\n",
    "\n",
    "            html += '</tr>'\n",
    "\n",
    "        html += '</table>'\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "388efe55-3502-4f24-be08-fdc40b651ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h5>Reg mul = 0</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (25) must match the size of tensor b (16) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4640\\4285128051.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                     \u001b[0ma_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraw_attention_inst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m                     \u001b[0ma_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_hat_h\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mINF\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mspe_tok_mask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_attention_inst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m                     \u001b[0ma_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_hat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"float\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (25) must match the size of tensor b (16) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "from attention_algorithms.plausibility_visu import hightlight_txt # function to highlight the text\n",
    "with torch.no_grad(): \n",
    "    for r in [0, 0.001, 0.002, 0.003, 0.004, 0.005, 0.08, 0.1, 0.4]:\n",
    "        display(HTML(f'<h5>Reg mul = {r}</h5>'))\n",
    "        model_outputs = {} # dictionnary for our display\n",
    "        for id_batch, elem in enumerate(test_dataloader) :\n",
    "\n",
    "            if id_batch > 1:\n",
    "                # only look at 5 sentences (batch of one here)\n",
    "                break\n",
    "\n",
    "            ids = elem[\"input_ids\"]\n",
    "            masks = elem[\"attention_masks\"]\n",
    "            labels = elem[\"labels\"]\n",
    "            a_true = list(np.array(elem[\"annotations\"][0].numpy(), dtype=float))\n",
    "            spe_tok_mask = torch.isin(ids, torch.tensor([0, 101, 102])).type(torch.uint8)[0]\n",
    "            it = 0\n",
    "            for model_name in models_dict:\n",
    "\n",
    "                # the attention_inst\n",
    "                raw_attention_inst = RawAttention(model = models_dict[f\"reg_mul={r}\"],\n",
    "                                                 input_ids = ids,\n",
    "                                                 attention_mask = masks,\n",
    "                                                 test_mod = False\n",
    "                                                 )\n",
    "                if it == 0:\n",
    "                    model_outputs[\"GROUNDTRUTH\"] = {\n",
    "                        '[CLS] + P + [SEP] + H + [SEP]':  [hightlight_txt(tokens = raw_attention_inst.tokens,\n",
    "                                                                        attention = a_true[0 : len(raw_attention_inst.tokens)])],\n",
    "                        'Label': list(np.array(labels.numpy(), dtype=\"float\"))\n",
    "                    }\n",
    "\n",
    "                    it += 1\n",
    "\n",
    "                for h in range(12):\n",
    "                    a_hat = raw_attention_inst.attention_tensor[0, 2, h, :, :].sum(dim=0)\n",
    "                    a_hat = torch.softmax(a_hat_h - INF*spe_tok_mask[0:len(raw_attention_inst.tokens)],dim=0)\n",
    "\n",
    "                    a_hat = list(np.array(a_hat.numpy(), dtype=\"float\"))\n",
    "\n",
    "                    model_outputs[f\"head{h}\"] =  {\n",
    "                        '[CLS] + P + [SEP] + H + [SEP]': [hightlight_txt(tokens = raw_attention_inst.tokens,\n",
    "                                                                        attention = a_hat)],\n",
    "                        'Label': list(np.array(labels.numpy(), dtype=\"float\"))\n",
    "                    }\n",
    "\n",
    "            display(HTML(html_render(model_outputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65aa1f8-a30e-4b45-8141-f6b7272919c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
